{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtrage collaboratif\n",
    "\n",
    "*ismael Bonneau*\n",
    "\n",
    "Le filtrage collaboratif (en anglais: collaborative filtering) est une méthode utilisée par les systèmes de recommandations.\n",
    "\n",
    "Une méthode de recommandation classique et de recommander à un utilisateur des objets similaires de celui qu'il a déjà aimé. Cette similarité, dans le cas d'une série ou d'un film par exemple peut se baser sur le genre, les acteurs en commun, le synopsis... Ainsi, si un utilisateur a aimé la série the punisher et luke cage, le système lui recommandera daredevil, shield agents, etc...\n",
    "Cette stratégie a un défaut: les recommandations manquent de diversité et n'incitent pas l'utilisateur à explorer le catalogue.\n",
    "\n",
    "Une deuxième approche est le **filtrage collaboratif**:\n",
    "il permet de réaliser des prédictions automatiques (\"filtrage\") des intérêts d'un utilisateur en se basant sur les préférences d'un grand nombre d'autres utilisateurs (\"collaboratif\"), afin de recommander des produits (films, séries, musique, articles sur un site de e-commerce...) pertinents pour un utilisateur.\n",
    "\n",
    "<img src=\"images/homer.png\" width=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------\n",
    "\n",
    "### Principe:\n",
    "\n",
    "L'hypothèse sous-jacente du filtrage collaboratif est que si une personne A a la même opinion qu'une personne B sur un sujet, A a plus de chance d'avoir la même opinion que B sur un autre sujet qu'une personne choisie au hasard.\n",
    "\n",
    "Le système commence donc d'abord par collecter des avis d'un grand nombre d'utilisateurs sur un grand nombre d'objets (dans notre cas, des séries). Cet avis peut prendre plusieurs formes (1-5 étoiles, note sur 10, j'aime/je n'aime pas...) \n",
    "\n",
    "Puis, pour un utilisateur A le système trouve les utilisateurs qui ont les goûts les plus similaires. A partir des goûts de ces utilisateurs les plus similaires, le système peut prédir à l'utilisateur A une note pour chacun des objets qu'il n'a pas noté. \n",
    "\n",
    "Plusieurs types d'approche existent:\n",
    "\n",
    "1) l'approche dite **memory-based**:\n",
    "<p>\n",
    "    Cette approche utilise les notes attribuées par les utilisateurs pour calculer la similarité entre les utilisateurs ou les objets. Elle se base sur un calcul de similarité et utilise des algorithmes classiques comme:\n",
    "    <ul>\n",
    "        <li>K plus proches voisins (K-NN) <a href=\"https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm\">wikipédia</a></li>\n",
    "        <li>Des mesures de similarité comme la similarité cosinus, la corrélation de Pearson...\n",
    "            <a href=\"\"></a></li>\n",
    "    </ul>\n",
    "</p>\n",
    "\n",
    "2) l'approche dite **model-based**: \n",
    "<p>\n",
    "    Cette approche utilise des techniques de machine learning et de data mining pour attribuer des notes couples utilisateur-objet. \n",
    "<ul>\n",
    "    <li>Analyse en composantes principales (PCA) <a href=\"https://en.wikipedia.org/wiki/Singular_value_decomposition\">wikipédia</a></li>\n",
    "    <li>Factorisation de matrice non négative (NNMF) <a href=\"https://en.wikipedia.org/wiki/Non-negative_matrix_factorization\">wikipédia</a></li>\n",
    "    <li>Bayesian Personalized Ranking (n'attribue pas de \"notes\" mais un classement) <a href=\"https://cran.r-project.org/web/packages/rrecsys/vignettes/b6_BPR.html\">lien</a></li>\n",
    "    <li>...Et bien d'autres (approches à base de clustering...)</li>\n",
    "</ul>\n",
    "</p>\n",
    "\n",
    "pour en savoir plus sur le filtrage collaboratif: <a href=\"https://en.wikipedia.org/wiki/Collaborative_filtering\">wikipédia (en anglais)</a>\n",
    "\n",
    "<img src=\"images/Classification-of-collaborative-filtering-algorithms.png\" width=\"600\" />\n",
    "\n",
    "image sources:\n",
    "\n",
    "<a href=\"https://www.researchgate.net/profile/Kan_Zheng/publication/303556519/figure/fig4/AS:614297214414873@1523471277992/Classification-of-collaborative-filtering-algorithms.png\">[1]</a> <a href=\"https://johnolamendy.wordpress.com/2015/10/14/collaborative-filtering-in-apache-spark/\">[2]</a>\n",
    "\n",
    "-------------------\n",
    "\n",
    "### Notre but:\n",
    "\n",
    "Nous allons mettre en oeuvre et comparer plusieurs approches de recommandation collaborative, en l'occurence les approches model-based. \n",
    "\n",
    "Notre but est d'implémenter et comparer qualitativement et quantitativement les algorithmes de factorisation de matrice non négative (NNMF), décomposition en valeurs singulières (SVD), Bayesian Personalized Ranking, et différentes fonctions de coûts associées, sur un jeu de données collectés sur le site imdb.\n",
    "\n",
    "### Données:\n",
    "\n",
    "Nous partons d'une base de ${m = 48705}$ utilisateurs ayant noté ${n = 892}$ séries. Ces données sont extraites du site <a href=\"https://www.imdb.com/\">imdb</a> (voir script scraping/scraping.py) et sont résumées dans une matrice de taille ${n,m}$ où chaque entrée ${(u, i)}$ de matrice contient la note que l'utilisateur ${u}$ a attribué à l'item (série) ${i}$, sur 10 (le site ayant choisi un système de notation sur 10 étoiles).\n",
    "\n",
    "---------------------\n",
    "\n",
    "### Rentrons dans le vif du sujet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import dok_matrix, csr_matrix #matrice \"sparse\"\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(color_codes=True)\n",
    "plt.style.use('seaborn-white')\n",
    "%matplotlib inline\n",
    "\n",
    "filename = \"userratings.csv\"\n",
    "tableSeries = \"series.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Récupérons les avis utilisateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "il y a 48705 utilisateurs et 892 séries\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(filename)\n",
    "print(\"il y a {} utilisateurs et {} séries\".format(df.shape[1], df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ci dessous**, les premières lignes de la matrice, avec en ligne les séries et en colonne les utilisateurs. On peut voir que la plupart des cases sont vides (NaN), les utilisateurs n'ayant noté que très peu de séries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ToddTee</th>\n",
       "      <th>bkoganbing</th>\n",
       "      <th>betwana</th>\n",
       "      <th>fabiogaucho</th>\n",
       "      <th>killer1h</th>\n",
       "      <th>rasadi27</th>\n",
       "      <th>michael_cure</th>\n",
       "      <th>MashedA</th>\n",
       "      <th>drarthurwells</th>\n",
       "      <th>...</th>\n",
       "      <th>jimjohnson-57331</th>\n",
       "      <th>tatianavoloshka</th>\n",
       "      <th>hectorgarcia-41182</th>\n",
       "      <th>allisonbryan-30611</th>\n",
       "      <th>timothyquaid</th>\n",
       "      <th>eduardoellis</th>\n",
       "      <th>Chris_Tsimpoukas</th>\n",
       "      <th>ToxicAvox</th>\n",
       "      <th>DinoLord94</th>\n",
       "      <th>bratdawg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0035665</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0042114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0043208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0047708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 48705 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0  ToddTee  bkoganbing  betwana  fabiogaucho  killer1h  rasadi27  \\\n",
       "0  tt0035665      NaN         NaN      NaN          NaN       NaN       NaN   \n",
       "1  tt0042114      NaN         NaN      NaN          NaN       NaN       NaN   \n",
       "2  tt0043208      NaN        10.0      NaN          NaN       NaN       NaN   \n",
       "3  tt0047708      NaN         NaN      NaN          NaN       NaN       NaN   \n",
       "\n",
       "   michael_cure  MashedA  drarthurwells    ...     jimjohnson-57331  \\\n",
       "0           NaN      NaN            NaN    ...                  NaN   \n",
       "1           NaN      NaN            NaN    ...                  NaN   \n",
       "2           NaN      NaN            NaN    ...                  NaN   \n",
       "3           NaN      NaN            NaN    ...                  NaN   \n",
       "\n",
       "   tatianavoloshka  hectorgarcia-41182  allisonbryan-30611  timothyquaid  \\\n",
       "0              NaN                 NaN                 NaN           NaN   \n",
       "1              NaN                 NaN                 NaN           NaN   \n",
       "2              NaN                 NaN                 NaN           NaN   \n",
       "3              NaN                 NaN                 NaN           NaN   \n",
       "\n",
       "   eduardoellis  Chris_Tsimpoukas  ToxicAvox  DinoLord94  bratdawg  \n",
       "0           NaN               NaN        NaN         NaN       NaN  \n",
       "1           NaN               NaN        NaN         NaN       NaN  \n",
       "2           NaN               NaN        NaN         NaN       NaN  \n",
       "3           NaN               NaN        NaN         NaN       NaN  \n",
       "\n",
       "[4 rows x 48705 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jetons un oeil à la distribution des données:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.55% des utilisateurs ont noté plus de 1 série (6598 total)\n",
      "1.38% des utilisateurs ont noté plus de 5 série (670 total)\n",
      "0.46% des utilisateurs ont noté plus de 10 série (226 total)\n",
      "\n",
      "\n",
      "98.54% des series ont reçu plus de 2 notes (879 total)\n",
      "69.62% des series ont reçu plus de 20 notes (621 total)\n",
      "35.87% des series ont reçu plus de 50 notes (320 total)\n",
      "19.28% des series ont reçu plus de 100 notes (172 total)\n"
     ]
    }
   ],
   "source": [
    "for seuil in [1, 5, 10]:\n",
    "    c = len([a for a in (df.count(axis=0) > seuil) if a])/df.shape[1]\n",
    "    print(\"{0:.2f}% des utilisateurs ont noté plus de \".format(\n",
    "        100*c)+str(seuil)+\" série (\"+str(int(c*df.shape[1]))+\" total)\")\n",
    "print(\"\\n\")   \n",
    "for seuil in [2, 20, 50, 100]:\n",
    "    c = len([a for a in (df.count(axis=1) > seuil) if a])/df.shape[0]\n",
    "    print(\"{0:.2f}% des series ont reçu plus de \".format(\n",
    "        100*c)+str(seuil)+\" notes (\"+str(int(c*df.shape[0]))+\" total)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/distribution_avis.png\" width=\"900\" />\n",
    "\n",
    "L'histogramme révèle que les utilisateurs donnent très peu d'avis: 86,5% d'entre eux n'ont noté qu'une série. Les séries ont quant à elle plus d'avis: près de 20% des séries ont reçu plus de 100 notes, et 70% des séries ont reçu au moins 20 notes. Il faut choisir un **seuil de coupure** pour éliminer les utilisateurs ayant trop peu noté: nous choisissons arbitrairement de couper en-dessous de 4. Pour les séries, on gardera celles ayant reçu au moins 4 notes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/distribution_notes.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.read_csv(tableSeries)\n",
    "series = series[[\"seriesname\", \"imdbId\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retirons les noms de série, et enlevons les utilisateurs ayant noté moins de 4 séries et les séries notées moins de 4 fois:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nous allons réaliser un mapping des imdbId de séries vers des entiers.\n",
    "#on mémorise le mapping entier -> série en gardant les noms de série.\n",
    "df.rename(columns={\"Unnamed: 0\":'item'}, inplace=True)\n",
    "df = df.loc[:, (df.count(axis=0) >= 4)] #enlever les utilisateurs ayant noté moins de 5 séries\n",
    "df = df.loc[(df.count(axis=1) >= 4), :] #enlever les séries ayant reçu moins de 4 notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_dict = []\n",
    "for imdbId in df[\"item\"]:\n",
    "    serie_dict.append(list(series[series[\"imdbId\"] == imdbId][\"seriesname\"])[0])\n",
    "    \n",
    "df = df.drop(columns=['item']) #enlever la colonne des noms de série\n",
    "df = df.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/distribution_notes_apresfiltrage.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masquage des valeurs manquantes:\n",
    "\n",
    "Nous allons créer une variable \"masque\" booléen, qui nous servira pour l'étape suivante. On obtient un tableau de même dimension, dans lequel False indique une valeur manquante (à masquer pour la suite) et True une valeur observée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>876</th>\n",
       "      <th>879</th>\n",
       "      <th>880</th>\n",
       "      <th>881</th>\n",
       "      <th>882</th>\n",
       "      <th>883</th>\n",
       "      <th>884</th>\n",
       "      <th>887</th>\n",
       "      <th>888</th>\n",
       "      <th>889</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bkoganbing</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>killer1h</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>santasa99</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qui_j</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BeneCumb</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 726 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0      1      2      3      4      5      6      7      8    \\\n",
       "bkoganbing  False  False   True  False   True   True   True   True  False   \n",
       "killer1h    False  False  False  False  False  False  False  False  False   \n",
       "santasa99   False  False  False  False  False  False  False  False  False   \n",
       "qui_j       False  False  False  False  False  False  False  False  False   \n",
       "BeneCumb    False  False  False  False  False  False  False  False  False   \n",
       "\n",
       "              10   ...      876    879    880    881    882    883    884  \\\n",
       "bkoganbing  False  ...    False  False  False  False  False  False  False   \n",
       "killer1h    False  ...    False  False   True  False  False  False  False   \n",
       "santasa99   False  ...    False  False  False  False  False  False  False   \n",
       "qui_j       False  ...    False  False  False  False  False  False  False   \n",
       "BeneCumb    False  ...    False  False  False   True  False  False  False   \n",
       "\n",
       "              887    888    889  \n",
       "bkoganbing  False  False  False  \n",
       "killer1h    False   True  False  \n",
       "santasa99   False  False  False  \n",
       "qui_j       False  False  False  \n",
       "BeneCumb    False  False  False  \n",
       "\n",
       "[5 rows x 726 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = df.notnull()\n",
    "mask.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = list(range(len(serie_dict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Factorization: principe\n",
    "\n",
    "Une des façons de faire du filtrage collaboratif par approche model-based est d'utiliser un algorithme de **factorisation de matrice**. \n",
    "\n",
    "On pose ${\\mathbf{R}}$ la matrice des notes, $\\mathbf{\\hat{R}}$ la matrice que l'on cherche à construire, contenant toutes les notes existantes et prédites. Cette matrice est de dimension ${m, n}$ avec ${m}$ le nombre d'utilisateurs et ${n}$ le nombre de séries. On va chercher à trouver deux matrices \"facteur\" $\\mathbf{U}$ et $\\mathbf{I}$ de dimension ${m, k}$ et ${k, n}$ de telle sorte que $\\mathbf{\\hat{R}}=\\mathbf{U}\\cdot\\mathbf{I}$ avec ${\\mathbf{\\hat{R}} \\approx \\mathbf{R}}$\n",
    "\n",
    "<img src=\"images/collaborative_filtering.png\" width=\"400\" />\n",
    "\n",
    "Les dimensions ${m}$ et ${n}$ étant connues à l'avance, c'est la dimension ${k}$ qu'il reste à fixer, et définir une \"fonction\" mathématique qui mesure à quel point les deux matrice $\\mathbf{R}$ (reconstituée) et la matrice originale sont proches.\n",
    "\n",
    "Ainsi, et d'après la définition du produit matriciel, chaque case de la matrice $R_{i,j}$ résultante est le résultat d'une combinaison linéaire de $U_{i,}$ et $I_{,j}$, c'est à dire d'un vecteur de dimension ${k}$ représentant l'utilisateur ${i}$ et d'un vecteur de dimension ${k}$ représentant l'item ${j}$.\n",
    "\n",
    "Il s'agit donc de projeter les utilisateurs et les items dans un espace de dimension ${k}$ ! On dit aussi qu'on apprend des _profils utilisateur_ et des _profils item_ sur ${k}$ variables latentes.\n",
    "\n",
    "Plusieurs algorithmes peuvent servir à réaliser une factorisation de matrice.\n",
    "\n",
    "### NMF (non negative matrix factorization): \n",
    "\n",
    "Un algorithme de factorisation de matrice simple. L'algorithme consiste en une descente de gradient sur une fonction d'erreur. L'algorithme ne tient pas compte des valeurs manquantes: Il effectue une descente de gradient uniquement sur les valeurs observées. Il \"apprend\" donc les relations entre items et utilisateurs sur les valeurs observées, pour ensuite pouvoir prédire les valeurs manquantes.\n",
    "\n",
    "On apprend donc deux matrices ${U}$ et ${I}$. \n",
    "la fonction d'erreur est ${e = ||(R -\\hat{R})^2|| + \\beta (||U||^2 + ||I||^2)}$.\n",
    "\n",
    "${\\beta}$ est le paramètre de régularization. Il nécessite d'être ajusté. Il sert à contrôler la \"taille\" des paramètres appris U et I en empêchant qu'ils deviennent trop grands, afin de s'assurer que l'on utilise que les variables latentes utiles. Pour en savoir plus sur la régularisation en machine learning: <a href=\"\">lien</a> \n",
    "\n",
    "La particularité de l'algorithme est qu'il intègre une contrainte sur les valeurs des matrices ${U}$ et ${I}$: elles doivent être **positives** (d'où le \"non negative\").<br>\n",
    "On a donc ${U_{i,k} \\geq 0}$ ${\\forall{(i,k)} \\in \\{1, ...,m\\} \\times \\{1, ...,k\\}}$ et ${I_{k,j} \\geq 0 \\forall{(k,j)} \\in \\{1, ...,k\\} \\times \\{1, ...,n\\}}$.\n",
    "\n",
    "Cette contrainte de non-négativité, qui fait la particularité de NMF présente deux avantages: 1) le modèle obtenu est expliquable: puisque les affinités sont toutes additives, on comprend plus aisément comment les intérêts se combinent entre eux.\n",
    "\n",
    "##### petit problème: données manquantes\n",
    "\n",
    "Un petit problème se pose dans la partie applicative: la matrice ${R}$ contient des données manquantes qui sont, dans une matrice sparse, interprétés comme des 0. Ce ne sont pourtant pas des notes de 0 mais bien une **absence de note** (notez la différence). Les implémentations des algorithmes de factorisation de matrice de scikit-learn ne prennent pas ce point en compte et cherchent à prédire des 0 à la place des valeurs manquantes. On ne peut donc pas utiliser les implémentations de scikit-learn et il faut définir notre propre implémentation (ou utiliser gensim/surprise).\n",
    "\n",
    "### Implémentation dans tensorflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf #ou n'importe quel autre framework de DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost: 4237797.342465\n",
      "cost: 404.733697\n",
      "cost: 272.362588\n",
      "cost: 218.924866\n",
      "cost: 192.677396\n",
      "cost: 177.274618\n",
      "cost: 166.912356\n",
      "cost: 159.372950\n",
      "cost: 153.620640\n",
      "cost: 149.069311\n",
      "cost: 145.385657\n",
      "cost: 142.400734\n",
      "cost: 139.988205\n",
      "cost: 137.992750\n",
      "cost: 136.299411\n",
      "cost: 134.838460\n",
      "cost: 133.561885\n",
      "cost: 132.434444\n",
      "cost: 131.434485\n",
      "cost: 130.544586\n",
      "cost: 129.743578\n",
      "cost: 129.020737\n",
      "cost: 128.380623\n",
      "cost: 127.806415\n",
      "cost: 127.277605\n",
      "cost: 126.785384\n",
      "cost: 126.322038\n",
      "cost: 125.887878\n",
      "cost: 125.482414\n",
      "cost: 125.107459\n"
     ]
    }
   ],
   "source": [
    "#latent factors\n",
    "k = 5\n",
    "shape = df.shape\n",
    "\n",
    "#biais global: moyenne de toutes les notes\n",
    "b = tf.constant(df.T.stack().values.mean(), name='bias')\n",
    "\n",
    "#biais utilisateur: vecteur de dimension (m, 1)\n",
    "#initialisé avec la moyenne des notes de chaque utilisateur\n",
    "bU = tf.Variable(df.mean(axis=1).values.astype(np.float64).T.reshape(-1,1), name=\"bU\")\n",
    "\n",
    "#biais item: vecteur de dimension (1, n)\n",
    "#initialisé avec la moyenne des notes de chaque item\n",
    "bI = tf.Variable(df.mean(axis=0).values.reshape(-1,1).T, name=\"bI\")\n",
    "\n",
    "#constante: la matrice R à reconstituer entièrement\n",
    "R = tf.constant(df.values / 10) #divisée par 10 pour obtenir des notes entre 0 et 1\n",
    "\n",
    "#variable tensorflow masque\n",
    "mask_tf = tf.Variable(mask.values)\n",
    "\n",
    "#variables tensorflow\n",
    "#U et I initialisés selon une loi normale et normalisés en divisant par k\n",
    "U = tf.Variable(np.random.normal(scale=1./k, size=(shape[0], k)).astype(np.float64), name=\"U\")\n",
    "I = tf.Variable(np.random.normal(scale=1./k, size=(k, shape[1])).astype(np.float64), name=\"I\")\n",
    "\n",
    "R_pred = bU + bI #biais user + biais item\n",
    "R_pred += tf.matmul(U, I) #embeddings\n",
    "R_pred += b #biais global\n",
    "\n",
    "#beta: paramètre de regularization\n",
    "beta = tf.constant(0.05, dtype=tf.float64, name=\"beta\")\n",
    "regularizer = beta * (tf.reduce_sum(tf.square(U)) + tf.reduce_sum(tf.square(I)))\n",
    "\n",
    "#cout de l'algo NMF, norme matricielle de R - R_pred\n",
    "cost = tf.reduce_sum(tf.pow(tf.boolean_mask(R, mask_tf) - tf.boolean_mask(R_pred, mask_tf), 2))\n",
    "cost += regularizer\n",
    "\n",
    "#contraintes de non-négativité de U et I\n",
    "clip_U = U.assign(tf.maximum(tf.zeros_like(U), U))\n",
    "clip_I = I.assign(tf.maximum(tf.zeros_like(I), I))\n",
    "clip = tf.group(clip_U, clip_I)\n",
    "\n",
    "alpha = 0.001 #learning rate\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "learning_rate = tf.train.exponential_decay(alpha, global_step, 10000, 0.96, staircase=True)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(alpha).minimize(cost, global_step=global_step)\n",
    "\n",
    "steps = 30000\n",
    "costs = []\n",
    "mses = []\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "for i in range(steps):\n",
    "    sess.run(optimizer)\n",
    "    sess.run(clip)\n",
    "    if i%1000==0:\n",
    "        prout = sess.run(cost)\n",
    "        print(\"cost: %f\" % prout)\n",
    "        costs.append((i, prout))\n",
    "            \n",
    "learnt_U = sess.run(U)\n",
    "learnt_I = sess.run(I)\n",
    "learnt_bU = sess.run(bU)\n",
    "learnt_bI = sess.run(bI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.title(\"cost en fonction du nb d'iterations\")\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"cost\")\n",
    "plt.plot([a for a,b in costs[1:]], [b for a,b in costs[1:]], label=\"cost\")\n",
    "#plt.plot([a for a,b in costs], mses, color=\"green\", label=\"MSE error\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1423, 726)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xptdr = np.round((df.T.stack().values.mean() + (learnt_bU + learnt_bI) + np.dot(learnt_U, learnt_I)) * 10)\n",
    "xptdr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On obtient bien la matrice reconstituée dans les dimensions voulues!\n",
    "\n",
    "### visualisons le résultat:\n",
    "\n",
    "Les matrices ${U}$ et ${I}$ apprises par NMF nous donnent une information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sauvegarde des embeddings appris pour les visualiser dans tensorboard\n",
    "np.savetxt(f\"imdb_vectors.tsv\", learnt_I.transpose(), delimiter=\"\\t\")\n",
    "with open(f\"imdb_metadata.tsv\",\"w\") as metadata_file:\n",
    "    for x in serie_dict: #hack for space\n",
    "        x = \" \".join(x.split(\"_\")[1:])\n",
    "        if len(x.strip()) == 0:\n",
    "            x = f\"space-{len(x)}\"\n",
    "        metadata_file.write(f\"{x}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avec k=10\n",
    "\n",
    "visualisation PCA en 3D, variance expliquée 82.8%\n",
    "\n",
    "<img src=\"images/pca_k10.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profil item 1\n",
      "\t\t5.35 37 \t\tStargate Universe\n",
      "\t\t6.80 51 \t\tSense8\n",
      "\t\t3.79 29 \t\tTeen Titans Go \n",
      "\t\t6.36 22 \t\tiCarly\n",
      "\t\t6.17 12 \t\tAccording to Jim\n",
      "profil item 2\n",
      "\t\t6.22 18 \t\tNikita\n",
      "\t\t7.16 43 \t\tTerminator The Sarah Connor Chronicles\n",
      "\t\t5.51 41 \t\tThe Strain\n",
      "\t\t5.77 22 \t\tGirls\n",
      "\t\t7.48 60 \t\tThe Office (US)\n",
      "profil item 3\n",
      "\t\t7.76 95 \t\tFriends\n",
      "\t\t6.03 34 \t\tGreys Anatomy\n",
      "\t\t7.29 21 \t\tCaprica\n",
      "\t\t6.85 59 \t\tThe Blacklist\n",
      "\t\t7.82 146 \t\tGame of Thrones\n",
      "profil item 4\n",
      "\t\t6.67 125 \t\tThe Walking Dead\n",
      "\t\t5.70 61 \t\tTwo and a Half Men\n",
      "\t\t7.33 15 \t\tBoy Meets World\n",
      "\t\t6.27 15 \t\tMajor Crimes\n",
      "\t\t5.22 46 \t\tFalling Skies\n",
      "profil item 5\n",
      "\t\t7.12 90 \t\tLost\n",
      "\t\t7.08 39 \t\tOrphan Black\n",
      "\t\t7.24 62 \t\tHannibal\n",
      "\t\t6.61 54 \t\tHomeland\n",
      "\t\t6.80 15 \t\tLittle Britain\n"
     ]
    }
   ],
   "source": [
    "def moyenneSerie(nomSerie):\n",
    "    i = serie_dict.index(nomSerie)\n",
    "    moyenne = df[i].mean()\n",
    "    count = len([a for a in df[i].notna() if a])\n",
    "    return moyenne, count\n",
    "\n",
    "for i in range(k):\n",
    "    lol = np.argsort(learnt_I.transpose()[:, i])[::-1][:5]\n",
    "    print(\"profil item %d\" % (i+1))\n",
    "    for j in range(5):\n",
    "        moyenne, count = moyenneSerie(serie_dict[lol[j]])\n",
    "        print(\"\\t\\t{0:.2f}\".format(moyenne), count, \"\\t\\t\"+\" \".join(serie_dict[lol[j]].split(\"_\")[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0 \t Raising the Bar\n",
      "5.0 \t Anger Management\n",
      "1.0 \t Ghost Whisperer\n",
      "1.0 \t Entourage\n",
      "1.0 \t Everybody Loves Raymond\n"
     ]
    }
   ],
   "source": [
    "lol = [(i,a) for i, a in enumerate(df.iloc[2].values) if not np.isnan(a)]\n",
    "lol.sort(key=lambda x: x[1])\n",
    "for i, rating in lol[::-1]:\n",
    "    print(rating,\"\\t\",\" \".join(serie_dict[i].split(\"_\")[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orphan Black\n",
      "Get Smart (1965)\n",
      "Little Britain\n",
      "Raising the Bar\n",
      "La Femme Nikita\n"
     ]
    }
   ],
   "source": [
    "for i in np.argsort(xptdr[2])[::-1][:5]:\n",
    "    print(\" \".join(serie_dict[i].split(\"_\")[1:]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
