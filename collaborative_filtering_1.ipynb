{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtrage collaboratif\n",
    "\n",
    "*ismael Bonneau*\n",
    "\n",
    "Le filtrage collaboratif (en anglais: collaborative filtering) est une méthode utilisée par les systèmes de recommandations.\n",
    "\n",
    "Elle permet de réaliser des prédictions automatiques (\"filtrage\") des intérêts d'un utilisateur en se basant sur les préférences d'un grand nombre d'autres utilisateurs (\"collaboratif\"), afin de recommander des produits (films, séries, musique, articles sur un site de e-commerce...) pertinents pour un utilisateur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/homer.png\" width=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------\n",
    "\n",
    "### Principe:\n",
    "\n",
    "L'hypothèse sous-jacente du filtrage collaboratif est que si une personne A a la même opinion qu'une personne B sur un sujet, A a plus de chance d'avoir la même opinion que B sur un autre sujet qu'une personne choisie au hasard.\n",
    "\n",
    "Le système commence donc d'abord par collecter des avis d'un grand nombre d'utilisateurs sur un grand nombre d'objets (dans notre cas, des séries). Cet avis peut prendre plusieurs formes (1-5 étoiles, note sur 10, j'aime/je n'aime pas...) \n",
    "\n",
    "Puis, pour un utilisateur A le système trouve les utilisateurs qui ont les goûts les plus similaires. A partir des goûts de ces utilisateurs les plus similaires, le système peut prédir à l'utilisateur A une note pour chacun des objets qu'il n'a pas noté. \n",
    "\n",
    "Plusieurs types d'approche existent:\n",
    "\n",
    "1) l'approche dite **memory-based**:\n",
    "<p>\n",
    "    Cette approche utilise les notes attribuées par les utilisateurs pour calculer la similarité entre les utilisateurs ou les objets. Elle se base sur un calcul de similarité et utilise des algorithmes classiques comme:\n",
    "    <ul>\n",
    "        <li>K plus proches voisins (K-NN) <a href=\"https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm\">wikipédia</a></li>\n",
    "        <li>Des mesures de similarité comme la similarité cosinus, la corrélation de Pearson...\n",
    "            <a href=\"\"></a></li>\n",
    "    </ul>\n",
    "</p>\n",
    "\n",
    "2) l'approche dite **model-based**: \n",
    "<p>\n",
    "    Cette approche utilise des techniques de machine learning et de data mining pour attribuer des notes couples utilisateur-objet. \n",
    "<ul>\n",
    "    <li>Analyse en composantes principales (PCA) <a href=\"https://en.wikipedia.org/wiki/Singular_value_decomposition\">wikipédia</a></li>\n",
    "    <li>Factorisation de matrice non négative (NNMF) <a href=\"https://en.wikipedia.org/wiki/Non-negative_matrix_factorization\">wikipédia</a></li>\n",
    "    <li>Bayesian Personalized Ranking (n'attribue pas de \"notes\" mais un classement) <a href=\"https://cran.r-project.org/web/packages/rrecsys/vignettes/b6_BPR.html\">lien</a></li>\n",
    "    <li>...Et bien d'autres (approches à base de clustering...)</li>\n",
    "</ul>\n",
    "</p>\n",
    "\n",
    "pour en savoir plus sur le filtrage collaboratif: <a href=\"https://en.wikipedia.org/wiki/Collaborative_filtering\">wikipédia (en anglais)</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Classification-of-collaborative-filtering-algorithms.png\" width=\"600\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image sources:\n",
    "\n",
    "https://www.researchgate.net/profile/Kan_Zheng/publication/303556519/figure/fig4/AS:614297214414873@1523471277992/Classification-of-collaborative-filtering-algorithms.png\n",
    "\n",
    "https://johnolamendy.wordpress.com/2015/10/14/collaborative-filtering-in-apache-spark/\n",
    "\n",
    "### Notre but:\n",
    "\n",
    "Nous allons mettre en oeuvre et comparer plusieurs approches de recommandation collaborative, en l'occurence les approches model-based. \n",
    "\n",
    "Notre but est d'implémenter et comparer qualitativement et quantitativement les algorithmes de factorisation de matrice non négative (NNMF), décomposition en valeurs singulières (SVD), Bayesian Personalized Ranking, et différentes fonctions de coûts associées, sur un jeu de données collectés sur le site imdb.\n",
    "\n",
    "### Données:\n",
    "\n",
    "Nous partons d'une base de ${m = 48705}$ utilisateurs ayant noté ${n = 892}$ séries. Ces données sont extraites du site <a href=\"https://www.imdb.com/\">imdb</a> (voir script scraping/scraping.py) et sont résumées dans une matrice de taille ${n,m}$ où chaque entrée ${(u, i)}$ de matrice contient la note que l'utilisateur ${u}$ a attribué à l'item (série) ${i}$, sur 10 (le site ayant choisi un système de notation sur 10 étoiles).\n",
    "\n",
    "---------------------\n",
    "\n",
    "### Rentrons dans le vif du sujet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.sparse import dok_matrix, csr_matrix #matrice \"sparse\"\n",
    "from sklearn.decomposition import NMF, TruncatedSVD #matrix factorization, nous y reviendrons plus tard\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "plt.style.use('seaborn-white')\n",
    "%matplotlib inline\n",
    "\n",
    "filename = \"userratings.csv\"\n",
    "tableSeries = \"series.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Récupérons les avis utilisateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "il y a 48705 utilisateurs et 892 séries\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(filename)\n",
    "\n",
    "print(\"il y a {} utilisateurs et {} séries\".format(df.shape[1], df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ci dessous**, les premières lignes de la matrice, avec en ligne les séries et en colonne les utilisateurs. On peut voir que la plupart des cases sont vides (NaN), les utilisateurs n'ayant noté que très peu de séries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bkoganbing</th>\n",
       "      <th>killer1h</th>\n",
       "      <th>santasa99</th>\n",
       "      <th>qui_j</th>\n",
       "      <th>BeneCumb</th>\n",
       "      <th>DegustateurDeChocolat</th>\n",
       "      <th>SonicStuart</th>\n",
       "      <th>DKosty123</th>\n",
       "      <th>jazebelle</th>\n",
       "      <th>insomniac_rod</th>\n",
       "      <th>...</th>\n",
       "      <th>chris_willson</th>\n",
       "      <th>michael-schaefer-34219</th>\n",
       "      <th>kevinmorice</th>\n",
       "      <th>mendelson77</th>\n",
       "      <th>pninson</th>\n",
       "      <th>montferrato</th>\n",
       "      <th>limona_razvan</th>\n",
       "      <th>kythia</th>\n",
       "      <th>Skylightmovies</th>\n",
       "      <th>bbgrl93</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 910 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bkoganbing  killer1h  santasa99  qui_j  BeneCumb  DegustateurDeChocolat  \\\n",
       "0         NaN       NaN        NaN    NaN       NaN                    NaN   \n",
       "1         NaN       NaN        NaN    NaN       NaN                    NaN   \n",
       "2        10.0       NaN        NaN    NaN       NaN                    NaN   \n",
       "3         NaN       NaN        NaN    NaN       NaN                    NaN   \n",
       "\n",
       "   SonicStuart  DKosty123  jazebelle  insomniac_rod   ...     chris_willson  \\\n",
       "0          NaN        NaN        NaN            NaN   ...               NaN   \n",
       "1          NaN        9.0        NaN            NaN   ...               NaN   \n",
       "2          NaN        9.0        NaN            NaN   ...               NaN   \n",
       "3          NaN        NaN        NaN            NaN   ...               NaN   \n",
       "\n",
       "   michael-schaefer-34219  kevinmorice  mendelson77  pninson  montferrato  \\\n",
       "0                     NaN          NaN          NaN      NaN          NaN   \n",
       "1                     NaN          NaN          NaN      NaN          NaN   \n",
       "2                     NaN          NaN          NaN      NaN          NaN   \n",
       "3                     NaN          NaN          NaN      NaN          NaN   \n",
       "\n",
       "   limona_razvan  kythia  Skylightmovies  bbgrl93  \n",
       "0            NaN     NaN             NaN      NaN  \n",
       "1            NaN     NaN             NaN      NaN  \n",
       "2            NaN     NaN             NaN      NaN  \n",
       "3            NaN     NaN             NaN      NaN  \n",
       "\n",
       "[4 rows x 910 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jetons un oeil à la distribution des données:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.55% des utilisateurs ont noté plus de 1 série (6598 total)\n",
      "1.38% des utilisateurs ont noté plus de 5 série (670 total)\n",
      "0.46% des utilisateurs ont noté plus de 10 série (226 total)\n",
      "\n",
      "\n",
      "98.54% des series ont reçu plus de 2 notes (879 total)\n",
      "69.62% des series ont reçu plus de 20 notes (621 total)\n",
      "35.87% des series ont reçu plus de 50 notes (320 total)\n",
      "19.28% des series ont reçu plus de 100 notes (172 total)\n"
     ]
    }
   ],
   "source": [
    "for seuil in [1, 5, 10]:\n",
    "    c = len([a for a in (df.count(axis=0) > seuil) if a])/df.shape[1]\n",
    "    print(\"{0:.2f}% des utilisateurs ont noté plus de \".format(\n",
    "        100*c)+str(seuil)+\" série (\"+str(int(c*df.shape[1]))+\" total)\")\n",
    "print(\"\\n\")   \n",
    "for seuil in [2, 20, 50, 100]:\n",
    "    c = len([a for a in (df.count(axis=1) > seuil) if a])/df.shape[0]\n",
    "    print(\"{0:.2f}% des series ont reçu plus de \".format(\n",
    "        100*c)+str(seuil)+\" notes (\"+str(int(c*df.shape[0]))+\" total)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/distribution_avis.png\" width=\"900\" />\n",
    "\n",
    "L'histogramme révèle que les utilisateurs donnent très peu d'avis: 86,5% d'entre eux n'ont noté qu'une série. Les séries ont quant à elle plus d'avis: près de 20% des séries ont reçu plus de 100 notes, et 70% des séries ont reçu au moins 20 notes. Il faut choisir un **seuil de coupure** pour éliminer les utilisateurs ayant trop peu noté: nous choisissons arbitrairement de couper en-dessous de 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.read_csv(tableSeries)\n",
    "series = series[[\"seriesname\", \"imdbId\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nous allons réaliser un mapping des imdbId de séries vers des entiers.\n",
    "#on mémorise le mapping entier -> série en gardant les noms de série.\n",
    "df.rename(columns={\"Unnamed: 0\":'item'}, inplace=True)\n",
    "serie_dict = []\n",
    "for imdbId in df[\"item\"]:\n",
    "    serie_dict.append(list(series[series[\"imdbId\"] == imdbId][\"seriesname\"])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retirons les noms de série, et enlevons les utilisateurs ayant noté moins de 5 séries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['item']) #enlever la colonne des noms de série\n",
    "df = df.loc[:, (df.count(axis=0) >= 4)] #enlever les utilisateurs ayant noté moins de 5 séries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On convertit le dataframe en matrice sparse scipy pour pouvoir travailler avec les algorithmes de machine learning. Une matrice \"sparse\" permet de stocker de manière efficace en mémoire des matrices de grande taille contenant peu de données, comme dans notre cas.\n",
    "\n",
    "<img src=\"images/sparse_matrix.png\" width=\"300\" />\n",
    "\n",
    "ci-dessus: un exemple de matrice sparse de taille ${8\\times8 = 64}$ alors qu'elle contient seulement ${12}$ valeurs. Avec une structure adaptée à cette particularité, seules les 12 valeurs seront stockées en mémoire, sans réserver inutilement de la place pour 64 valeurs.\n",
    "\n",
    "Avant de convertir les données en matrice sparse, nous allons les normaliser: nous allons centrer les données, c'est à dire soustraire à chaque colonne (chaque utilisateur) sa moyenne. Ainsi chaque note sera normalisée par rapport à la moyenne des notes données par cet utilisateur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "umeans = []\n",
    "for user in df:\n",
    "    mean = df[user].mean()\n",
    "    df[user] = df[user] - mean\n",
    "    umeans.append(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### passage en matrice sparse et construction du train/test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nouvelles dimensions de la matrice:  (1423, 892)\n",
      "nombre de notes dans le train set  10182\n",
      "nombre de notes dans le test set  1198\n"
     ]
    }
   ],
   "source": [
    "mat = dok_matrix((df.values.shape[1], df.values.shape[0]), dtype=np.float32) #créer matrice sparse de dimension voulue\n",
    "test = []\n",
    "\n",
    "ind = 0\n",
    "for i in range(df.values.shape[1]):\n",
    "    for j in range(df.values.shape[0]):\n",
    "        if not np.isnan(df.values[j,i]):\n",
    "            if ind % 10 == 0:\n",
    "                test.append((i,j,float(df.values[j,i])))\n",
    "            else:\n",
    "                mat[i,j] = float(df.values[j,i]) #on en profite pour transposer car le dataframe de base est en item x user\n",
    "            ind += 1 \n",
    "print(\"nouvelles dimensions de la matrice: \", mat.shape)\n",
    "print(\"nombre de notes dans le train set \", mat.nnz)\n",
    "print(\"nombre de notes dans le test set \", len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et voilà notre matrice sparse! Nos données sont prêtes, nous pouvons passer à l'étape suivante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-negative Matrix Factorization:\n",
    "\n",
    "Une des façons de faire du filtrage collaboratif par approche model-based est d'utiliser un algorithme de **factorisation de matrice**. \n",
    "\n",
    "On pose $\\mathbf{R}$ la matrice que l'on cherche à prédire, contenant toutes les notes existantes et prédites. Cette matrice est de dimension ${m, n}$ avec ${m}$ le nombre d'utilisateurs et ${n}$ le nombre de séries. On va chercher à trouver deux matrices \"facteur\" $\\mathbf{U}$ et $\\mathbf{I}$ de dimension ${m, k}$ et ${k, n}$ de telle sorte que $\\mathbf{R}\\approx\\mathbf{U}\\cdot\\mathbf{I}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/collaborative_filtering.png\" width=\"400\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les dimensions ${m}$ et ${n}$ étant connues à l'avance, c'est la dimension ${k}$ qu'il reste à fixer, et définir une \"fonction\" mathématique qui mesure à quel point les deux matrice $\\mathbf{R}$ (reconstituée) et la matrice originale sont proches.\n",
    "\n",
    "Ainsi, et d'après la définition du produit matriciel, chaque case de la matrice $R_{i,j}$ résultante est le résultat d'une combinaison linéaire de $U_{i,}$ et $I_{,j}$, c'est à dire d'un vecteur de dimension ${k}$ représentant l'utilisateur ${i}$ et d'un vecteur de dimension ${k}$ représentant l'item ${j}$.\n",
    "\n",
    "Il s'agit donc de projeter les utilisateurs et les items dans un espace de dimension ${k}$ !\n",
    "\n",
    "Plusieurs algorithmes peuvent servir à réaliser une factorisation de matrice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD (singular value decomposition)\n",
    "\n",
    "L'algorithme décompose donc ${R}$ comme un produit de 2 matrices ${R\\approx U\\cdot I^\\top}$. Le paramètre k est très important. \n",
    "\n",
    "Comme nos données sont normalisées de façon à ne modéliser que la déviation par rapport à la moyenne, la règle de prédiction sera: ${r_{u,i} = \\mu_{u}+U_u\\cdot I_i^\\top}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1423, 150) (892, 150)\n"
     ]
    }
   ],
   "source": [
    "#n_components: le paramètre k\n",
    "model = TruncatedSVD(n_components=150)\n",
    "U = model.fit_transform(mat) #utilisateurs\n",
    "I = model.components_ #items\n",
    "#sigma = np.diag(model2.singular_values_) #sigma, sous forme de matrice diagonale\n",
    "I = I.transpose()\n",
    "\n",
    "print(U.shape, I.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On obtient bien les matrices voulues dans les bonnes dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:\n",
      "MSE: 0.82574844\n",
      "MAE: 0.55578387\n",
      "Test Error:\n",
      "MSE: 4.513658130577963\n",
      "MAE: 1.5378881834437736\n"
     ]
    }
   ],
   "source": [
    "def MSE_err(truth,pred):\n",
    "    \"\"\"\n",
    "    mean squarred error\n",
    "    \"\"\"\n",
    "    return np.mean(np.power(np.array(truth-pred),2))\n",
    "\n",
    "def MAE_err(truth,pred):\n",
    "    \"\"\"\n",
    "    mean absolute error\n",
    "    \"\"\"\n",
    "    return np.mean(np.abs(np.array(truth-pred)))\n",
    "\n",
    "def pred_func(uid,iid):\n",
    "    return np.dot(U[uid], I[iid])\n",
    "\n",
    "\n",
    "def pred(uid,iid):\n",
    "    return np.dot(U[uid], I[iid]) + umeans[uid]\n",
    "\n",
    "truth_tr = np.array([rating for (uid,iid),rating in mat.items()])\n",
    "truth_te = np.array([rating for uid,iid,rating in test])\n",
    "\n",
    "prediction_tr = np.array([pred_func(u,i) for (u,i),rating in mat.items()])\n",
    "prediction_te = np.array([pred_func(u,i) for u,i,rating in test])\n",
    "\n",
    "print(\"Training Error:\")\n",
    "print(\"MSE:\",  MSE_err(prediction_tr,truth_tr))\n",
    "print(\"MAE:\",  MAE_err(prediction_tr,truth_tr))\n",
    "\n",
    "print(\"Test Error:\")\n",
    "print(\"MSE:\",  MSE_err(prediction_te,truth_te))\n",
    "print(\"MAE:\",  MAE_err(prediction_te,truth_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
