{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtrage collaboratif\n",
    "\n",
    "*ismael Bonneau*\n",
    "\n",
    "Le filtrage collaboratif (en anglais: collaborative filtering) est une méthode utilisée par les systèmes de recommandations.\n",
    "\n",
    "Une méthode de recommandation classique et de recommander à un utilisateur des objets similaires de celui qu'il a déjà aimé. Cette similarité, dans le cas d'une série ou d'un film par exemple peut se baser sur le genre, les acteurs en commun, le synopsis... Ainsi, si un utilisateur a aimé la série the punisher et luke cage, le système lui recommandera daredevil, shield agents, etc...\n",
    "Cette stratégie a un défaut: les recommandations manquent de diversité et n'incitent pas l'utilisateur à explorer le catalogue.\n",
    "\n",
    "Une deuxième approche est le **filtrage collaboratif**:\n",
    "il permet de réaliser des prédictions automatiques (\"filtrage\") des intérêts d'un utilisateur en se basant sur les préférences d'un grand nombre d'autres utilisateurs (\"collaboratif\"), afin de recommander des produits (films, séries, musique, articles sur un site de e-commerce...) pertinents pour un utilisateur.\n",
    "\n",
    "<img src=\"images/homer.png\" width=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------\n",
    "\n",
    "### Principe:\n",
    "\n",
    "L'hypothèse sous-jacente du filtrage collaboratif est que si une personne A a la même opinion qu'une personne B sur un sujet, A a plus de chance d'avoir la même opinion que B sur un autre sujet qu'une personne choisie au hasard.\n",
    "\n",
    "Le système commence donc d'abord par collecter des avis d'un grand nombre d'utilisateurs sur un grand nombre d'objets (dans notre cas, des séries). Cet avis peut prendre plusieurs formes (1-5 étoiles, note sur 10, j'aime/je n'aime pas...) \n",
    "\n",
    "Puis, pour un utilisateur A le système trouve les utilisateurs qui ont les goûts les plus similaires. A partir des goûts de ces utilisateurs les plus similaires, le système peut prédir à l'utilisateur A une note pour chacun des objets qu'il n'a pas noté. \n",
    "\n",
    "Plusieurs types d'approche existent:\n",
    "\n",
    "1) l'approche dite **memory-based**:\n",
    "<p>\n",
    "    Cette approche utilise les notes attribuées par les utilisateurs pour calculer la similarité entre les utilisateurs ou les objets. Elle se base sur un calcul de similarité et utilise des algorithmes classiques comme:\n",
    "    <ul>\n",
    "        <li>K plus proches voisins (K-NN) <a href=\"https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm\">wikipédia</a></li>\n",
    "        <li>Des mesures de similarité comme la similarité cosinus, la corrélation de Pearson...\n",
    "            <a href=\"\"></a></li>\n",
    "    </ul>\n",
    "</p>\n",
    "\n",
    "2) l'approche dite **model-based**: \n",
    "<p>\n",
    "    Cette approche utilise des techniques de machine learning et de data mining pour attribuer des notes couples utilisateur-objet. \n",
    "<ul>\n",
    "    <li>Analyse en composantes principales (PCA) <a href=\"https://en.wikipedia.org/wiki/Singular_value_decomposition\">wikipédia</a></li>\n",
    "    <li>Factorisation de matrice non négative (NNMF) <a href=\"https://en.wikipedia.org/wiki/Non-negative_matrix_factorization\">wikipédia</a></li>\n",
    "    <li>Bayesian Personalized Ranking (n'attribue pas de \"notes\" mais un classement) <a href=\"https://cran.r-project.org/web/packages/rrecsys/vignettes/b6_BPR.html\">lien</a></li>\n",
    "    <li>...Et bien d'autres (approches à base de clustering...)</li>\n",
    "</ul>\n",
    "</p>\n",
    "\n",
    "pour en savoir plus sur le filtrage collaboratif: <a href=\"https://en.wikipedia.org/wiki/Collaborative_filtering\">wikipédia (en anglais)</a>\n",
    "\n",
    "<img src=\"images/Classification-of-collaborative-filtering-algorithms.png\" width=\"600\" />\n",
    "\n",
    "image sources:\n",
    "\n",
    "<a href=\"https://www.researchgate.net/profile/Kan_Zheng/publication/303556519/figure/fig4/AS:614297214414873@1523471277992/Classification-of-collaborative-filtering-algorithms.png\">[1]</a> <a href=\"https://johnolamendy.wordpress.com/2015/10/14/collaborative-filtering-in-apache-spark/\">[2]</a>\n",
    "\n",
    "-------------------\n",
    "\n",
    "### Notre but:\n",
    "\n",
    "Nous allons mettre en oeuvre et comparer plusieurs approches de recommandation collaborative, en l'occurence les approches model-based. \n",
    "\n",
    "Notre but est d'implémenter et comparer qualitativement et quantitativement les algorithmes de factorisation de matrice non négative (NNMF), décomposition en valeurs singulières (SVD), Bayesian Personalized Ranking, et différentes fonctions de coûts associées, sur un jeu de données collectés sur le site imdb.\n",
    "\n",
    "### Données:\n",
    "\n",
    "Nous partons d'une base de ${m = 48705}$ utilisateurs ayant noté ${n = 892}$ séries. Ces données sont extraites du site <a href=\"https://www.imdb.com/\">imdb</a> (voir script scraping/scraping.py) et sont résumées dans une matrice de taille ${n,m}$ où chaque entrée ${(u, i)}$ de matrice contient la note que l'utilisateur ${u}$ a attribué à l'item (série) ${i}$, sur 10 (le site ayant choisi un système de notation sur 10 étoiles).\n",
    "\n",
    "Nous allons utiliser des algorithmes implémentés \"à la main\" par nous-mêmes, ainsi que la librairie python <a href=\"http://surpriselib.com/\">Surprise</a>, qui est une librairie contenant différents algorithmes de machine learning pour la recommandation.\n",
    "\n",
    "---------------------\n",
    "\n",
    "### Rentrons dans le vif du sujet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import dok_matrix, csr_matrix #matrice \"sparse\"\n",
    "import seaborn as sns\n",
    "\n",
    "from surprise import SVD, NMF #matrix factorization, nous y reviendrons plus tard\n",
    "from surprise.accuracy import rmse, mae #mesures d'evaluation\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "sns.set(color_codes=True)\n",
    "plt.style.use('seaborn-white')\n",
    "%matplotlib inline\n",
    "\n",
    "filename = \"userratings.csv\"\n",
    "tableSeries = \"series.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Récupérons les avis utilisateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "il y a 48705 utilisateurs et 892 séries\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(filename)\n",
    "\n",
    "print(\"il y a {} utilisateurs et {} séries\".format(df.shape[1], df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ci dessous**, les premières lignes de la matrice, avec en ligne les séries et en colonne les utilisateurs. On peut voir que la plupart des cases sont vides (NaN), les utilisateurs n'ayant noté que très peu de séries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bkoganbing</th>\n",
       "      <th>killer1h</th>\n",
       "      <th>santasa99</th>\n",
       "      <th>qui_j</th>\n",
       "      <th>BeneCumb</th>\n",
       "      <th>DegustateurDeChocolat</th>\n",
       "      <th>SonicStuart</th>\n",
       "      <th>DKosty123</th>\n",
       "      <th>jazebelle</th>\n",
       "      <th>insomniac_rod</th>\n",
       "      <th>...</th>\n",
       "      <th>chris_willson</th>\n",
       "      <th>michael-schaefer-34219</th>\n",
       "      <th>kevinmorice</th>\n",
       "      <th>mendelson77</th>\n",
       "      <th>pninson</th>\n",
       "      <th>montferrato</th>\n",
       "      <th>limona_razvan</th>\n",
       "      <th>kythia</th>\n",
       "      <th>Skylightmovies</th>\n",
       "      <th>bbgrl93</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 910 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bkoganbing  killer1h  santasa99  qui_j  BeneCumb  DegustateurDeChocolat  \\\n",
       "0         NaN       NaN        NaN    NaN       NaN                    NaN   \n",
       "1         NaN       NaN        NaN    NaN       NaN                    NaN   \n",
       "2        10.0       NaN        NaN    NaN       NaN                    NaN   \n",
       "3         NaN       NaN        NaN    NaN       NaN                    NaN   \n",
       "\n",
       "   SonicStuart  DKosty123  jazebelle  insomniac_rod   ...     chris_willson  \\\n",
       "0          NaN        NaN        NaN            NaN   ...               NaN   \n",
       "1          NaN        9.0        NaN            NaN   ...               NaN   \n",
       "2          NaN        9.0        NaN            NaN   ...               NaN   \n",
       "3          NaN        NaN        NaN            NaN   ...               NaN   \n",
       "\n",
       "   michael-schaefer-34219  kevinmorice  mendelson77  pninson  montferrato  \\\n",
       "0                     NaN          NaN          NaN      NaN          NaN   \n",
       "1                     NaN          NaN          NaN      NaN          NaN   \n",
       "2                     NaN          NaN          NaN      NaN          NaN   \n",
       "3                     NaN          NaN          NaN      NaN          NaN   \n",
       "\n",
       "   limona_razvan  kythia  Skylightmovies  bbgrl93  \n",
       "0            NaN     NaN             NaN      NaN  \n",
       "1            NaN     NaN             NaN      NaN  \n",
       "2            NaN     NaN             NaN      NaN  \n",
       "3            NaN     NaN             NaN      NaN  \n",
       "\n",
       "[4 rows x 910 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jetons un oeil à la distribution des données:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.55% des utilisateurs ont noté plus de 1 série (6598 total)\n",
      "1.38% des utilisateurs ont noté plus de 5 série (670 total)\n",
      "0.46% des utilisateurs ont noté plus de 10 série (226 total)\n",
      "\n",
      "\n",
      "98.54% des series ont reçu plus de 2 notes (879 total)\n",
      "69.62% des series ont reçu plus de 20 notes (621 total)\n",
      "35.87% des series ont reçu plus de 50 notes (320 total)\n",
      "19.28% des series ont reçu plus de 100 notes (172 total)\n"
     ]
    }
   ],
   "source": [
    "for seuil in [1, 5, 10]:\n",
    "    c = len([a for a in (df.count(axis=0) > seuil) if a])/df.shape[1]\n",
    "    print(\"{0:.2f}% des utilisateurs ont noté plus de \".format(\n",
    "        100*c)+str(seuil)+\" série (\"+str(int(c*df.shape[1]))+\" total)\")\n",
    "print(\"\\n\")   \n",
    "for seuil in [2, 20, 50, 100]:\n",
    "    c = len([a for a in (df.count(axis=1) > seuil) if a])/df.shape[0]\n",
    "    print(\"{0:.2f}% des series ont reçu plus de \".format(\n",
    "        100*c)+str(seuil)+\" notes (\"+str(int(c*df.shape[0]))+\" total)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/distribution_avis.png\" width=\"900\" />\n",
    "\n",
    "L'histogramme révèle que les utilisateurs donnent très peu d'avis: 86,5% d'entre eux n'ont noté qu'une série. Les séries ont quant à elle plus d'avis: près de 20% des séries ont reçu plus de 100 notes, et 70% des séries ont reçu au moins 20 notes. Il faut choisir un **seuil de coupure** pour éliminer les utilisateurs ayant trop peu noté: nous choisissons arbitrairement de couper en-dessous de 4. Pour les séries, on gardera celles ayant reçu au moins 4 notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.read_csv(tableSeries)\n",
    "series = series[[\"seriesname\", \"imdbId\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nous allons réaliser un mapping des imdbId de séries vers des entiers.\n",
    "#on mémorise le mapping entier -> série en gardant les noms de série.\n",
    "df.rename(columns={\"Unnamed: 0\":'item'}, inplace=True)\n",
    "serie_dict = []\n",
    "for imdbId in df[\"item\"]:\n",
    "    serie_dict.append(list(series[series[\"imdbId\"] == imdbId][\"seriesname\"])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retirons les noms de série, et enlevons les utilisateurs ayant noté moins de 4 séries et les séries notées moins de 4 fois:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['item']) #enlever la colonne des noms de série\n",
    "df = df.loc[:, (df.count(axis=0) >= 4)] #enlever les utilisateurs ayant noté moins de 5 séries\n",
    "df = df.loc[(df.count(axis=1) >= 4), :] #enlever les séries ayant reçu moins de 4 notes\n",
    "df = df.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masquage des valeurs manquantes:\n",
    "\n",
    "Nous allons créer une variable \"masque\" booléen, qui nous servira pour l'étape suivante. On obtient un tableau de même dimension, dans lequel False indique une valeur manquante (à masquer pour la suite) et True une valeur observée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>876</th>\n",
       "      <th>879</th>\n",
       "      <th>880</th>\n",
       "      <th>881</th>\n",
       "      <th>882</th>\n",
       "      <th>883</th>\n",
       "      <th>884</th>\n",
       "      <th>887</th>\n",
       "      <th>888</th>\n",
       "      <th>889</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bkoganbing</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>killer1h</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>santasa99</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qui_j</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BeneCumb</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 666 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0      1      2      3      4      5      7      8      10   \\\n",
       "bkoganbing  False  False   True  False   True   True   True  False  False   \n",
       "killer1h    False  False  False  False  False  False  False  False  False   \n",
       "santasa99   False  False  False  False  False  False  False  False  False   \n",
       "qui_j       False  False  False  False  False  False  False  False  False   \n",
       "BeneCumb    False  False  False  False  False  False  False  False  False   \n",
       "\n",
       "              11   ...      876    879    880    881    882    883    884  \\\n",
       "bkoganbing  False  ...    False  False  False  False  False  False  False   \n",
       "killer1h    False  ...    False  False   True  False  False  False  False   \n",
       "santasa99   False  ...    False  False  False  False  False  False  False   \n",
       "qui_j       False  ...    False  False  False  False  False  False  False   \n",
       "BeneCumb    False  ...    False  False  False   True  False  False  False   \n",
       "\n",
       "              887    888    889  \n",
       "bkoganbing  False  False  False  \n",
       "killer1h    False   True  False  \n",
       "santasa99   False  False  False  \n",
       "qui_j       False  False  False  \n",
       "BeneCumb    False  False  False  \n",
       "\n",
       "[5 rows x 666 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = df.notnull()\n",
    "mask.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Factorization: principe\n",
    "\n",
    "Une des façons de faire du filtrage collaboratif par approche model-based est d'utiliser un algorithme de **factorisation de matrice**. \n",
    "\n",
    "On pose ${\\mathbf{R}}$ la matrice des notes, $\\mathbf{\\hat{R}}$ la matrice que l'on cherche à construire, contenant toutes les notes existantes et prédites. Cette matrice est de dimension ${m, n}$ avec ${m}$ le nombre d'utilisateurs et ${n}$ le nombre de séries. On va chercher à trouver deux matrices \"facteur\" $\\mathbf{U}$ et $\\mathbf{I}$ de dimension ${m, k}$ et ${k, n}$ de telle sorte que $\\mathbf{\\hat{R}}=\\mathbf{U}\\cdot\\mathbf{I}$ avec ${\\mathbf{\\hat{R}} \\approx \\mathbf{R}}$\n",
    "\n",
    "<img src=\"images/collaborative_filtering.png\" width=\"400\" />\n",
    "\n",
    "Les dimensions ${m}$ et ${n}$ étant connues à l'avance, c'est la dimension ${k}$ qu'il reste à fixer, et définir une \"fonction\" mathématique qui mesure à quel point les deux matrice $\\mathbf{R}$ (reconstituée) et la matrice originale sont proches.\n",
    "\n",
    "Ainsi, et d'après la définition du produit matriciel, chaque case de la matrice $R_{i,j}$ résultante est le résultat d'une combinaison linéaire de $U_{i,}$ et $I_{,j}$, c'est à dire d'un vecteur de dimension ${k}$ représentant l'utilisateur ${i}$ et d'un vecteur de dimension ${k}$ représentant l'item ${j}$.\n",
    "\n",
    "Il s'agit donc de projeter les utilisateurs et les items dans un espace de dimension ${k}$ ! On dit aussi qu'on apprend des _profils utilisateur_ et des _profils item_ sur ${k}$ variables latentes.\n",
    "\n",
    "Plusieurs algorithmes peuvent servir à réaliser une factorisation de matrice.\n",
    "\n",
    "### NMF (non negative matrix factorization): \n",
    "\n",
    "Un algorithme de factorisation de matrice simple. L'algorithme consiste en une descente de gradient sur une fonction d'erreur. L'algorithme ne tient pas compte des valeurs manquantes: Il effectue une descente de gradient uniquement sur les valeurs observées. Il \"apprend\" donc les relations entre items et utilisateurs sur les valeurs observées, pour ensuite pouvoir prédire les valeurs manquantes.\n",
    "\n",
    "L'algorithme apprend donc une matrice ${U}$ et ${I}$. \n",
    "la fonction d'erreur est ${e = ||(R -\\hat{R})^2|| + \\beta (||U||^2 + ||I||^2)}$.\n",
    "\n",
    "il intègre une contrainte sur les valeurs des matrices ${U}$ et ${I}$: elles doivent être **positives**.<br>\n",
    "On a donc ${U_{i,k} \\geq 0}$ ${\\forall{(i,k)} \\in \\{1, ...,m\\} \\times \\{1, ...,k\\}}$ et ${I_{k,j} \\geq 0 \\forall{(k,j)} \\in \\{1, ...,k\\} \\times \\{1, ...,n\\}}$.\n",
    "\n",
    "\n",
    "${\\beta}$ est le paramètre de régularization. Il nécessite d'être ajusté.\n",
    "\n",
    "##### petit problème: données manquantes\n",
    "\n",
    "Un petit problème se pose dans la partie applicative: la matrice ${R}$ contient des données manquantes qui sont, dans une matrice sparse, interprétés comme des 0. Ce ne sont pourtant pas des notes de 0 mais bien une **absence de note** (notez la différence). Les implémentations des algorithmes de factorisation de matrice de scikit-learn ne prennent pas ce point en compte et cherchent à prédire des 0 à la place des valeurs manquantes. On ne peut donc pas utiliser les implémentations de scikit-learn et il faut définir notre propre implémentation (ou utiliser gensim/surprise).\n",
    "\n",
    "### Implémentation dans tensorflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#latent factors\n",
    "k = 100 \n",
    "shape = df.shape\n",
    "\n",
    "#constante: la matrice R à reconstituer entièrement\n",
    "R = tf.constant(df.values)\n",
    "\n",
    "#variable tensorflow masque\n",
    "mask_tf = tf.Variable(mask.values)\n",
    "\n",
    "#variables tensorflow\n",
    "#U et I initialisés selon une loi normale et normalisés en divisant par k\n",
    "U = tf.Variable(np.random.normal(scale=1./k, size=(shape[0], k)).astype(np.float64), name=\"U\")\n",
    "I =  tf.Variable(np.random.normal(scale=1./k, size=(k, shape[1])).astype(np.float64), name=\"I\")\n",
    "\n",
    "R_pred = tf.matmul(U, I)\n",
    "\n",
    "#beta: paramètre de regularization\n",
    "beta = tf.constant(0.01, dtype=tf.float64, name=\"beta\")\n",
    "\n",
    "#cout de l'algo NMF, norme matricielle de R - R_pred\n",
    "cost = tf.reduce_sum(tf.pow(tf.boolean_mask(R, mask_tf) - tf.boolean_mask(R_pred, mask_tf), 2)) \\\n",
    "+ beta * (tf.reduce_sum(tf.pow(U, 2)) + tf.reduce_sum(tf.pow(I, 2)))\n",
    "\n",
    "#contraintes de non-négativité de U et I\n",
    "clip_U = U.assign(tf.maximum(tf.zeros_like(U), U))\n",
    "clip_I = I.assign(tf.maximum(tf.zeros_like(I), I))\n",
    "clip = tf.group(clip_U, clip_I)\n",
    "\n",
    "alpha = 0.001\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(alpha).minimize(cost)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "steps = 2000\n",
    "costs = []\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(steps):\n",
    "        sess.run(train_step)\n",
    "        sess.run(clip)\n",
    "        if i%100==0:\n",
    "            prout = sess.run(cost)\n",
    "            #print(\"\\nCost: %f\" % prout)\n",
    "            #print(\"*\"*40)\n",
    "            costs.append((i, prout))\n",
    "    learnt_U = sess.run(U)\n",
    "    learnt_I = sess.run(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"cost en fonction du nb d'iterations\")\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"cost\")\n",
    "plt.plot([a for a,b in costs], [b for a,b in costs])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1423, 666)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_reconstitue = np.dot(learnt_U, learnt_I)\n",
    "R_reconstitue.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD (singular value decomposition)\n",
    "\n",
    "L'algorithme décompose donc ${R}$ comme un produit de 3 matrices ${R = U\\cdot \\Sigma \\cdot I^\\top}$. \n",
    "\n",
    "${\\Sigma}$ est une matrice carrée diagonale de taille ${k\\times k}$ contenant les ${k}$ **valeurs propres** de la matrice.\n",
    "\n",
    "Comme nos données sont normalisées de façon à ne modéliser que la déviation par rapport à la moyenne, la règle de prédiction sera: ${r_{u,i} = \\mu_{u}+U_u\\cdot I_i^\\top}$\n",
    "\n",
    "\n",
    "Avant d'utiliser les données, nous allons les normaliser: nous allons centrer les données, c'est à dire soustraire à chaque colonne (chaque utilisateur) sa moyenne. Ainsi chaque note sera normalisée par rapport à la moyenne des notes données par cet utilisateur."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
